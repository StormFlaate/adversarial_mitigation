{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import torch # Import the Pytorch library\n",
    "import torchvision # Import the torchvision library\n",
    "from torchvision import datasets, transforms # Import the transforms module from torchvision\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image # Import the Image module from the Python Imaging Library (PIL)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import urllib # Import the urllib library for URL handling\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from customDataset import ISICDataset\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "from data_exploration_helper import dataset_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set 2018\n",
    "TRAIN_2018_LABELS: str = \"./data/ISIC2018_Training_GroundTruth.csv\"\n",
    "TRAIN_2018_ROOT_DIR: str = \"./data/ISIC2018_Training_Input\"\n",
    "\n",
    "TEST_2018_LABELS: str = \"./data/ISIC2018_Validation_GroundTruth.csv\"\n",
    "TEST_2018_ROOT_DIR: str = \"./data/ISIC2018_Validation_Input\"\n",
    "\n",
    "# Dataset 2019 - has not been split into train and test\n",
    "DATASET_2019_LABELS: str = \"./data/ISIC_2019_Training_GroundTruth.csv\"\n",
    "DATASET_2019_ROOT_DIR: str = \"./data/ISIC_2019_Training_Input\"\n",
    "\n",
    "# Define image pre-processing steps\n",
    "preprocess_inceptionv3 = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(299), # Resize the image to 299x299 pixels\n",
    "    transforms.CenterCrop(299), # Crop the image to 299x299 pixels (removing any extra pixels)\n",
    "    transforms.ToTensor(), # Convert the image to a Pytorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the image using the pre-trained model's mean and standard deviation\n",
    "])\n",
    "\n",
    "# Training set 2018 - custom class\n",
    "train_dataset_2018 = ISICDataset(\n",
    "    csv_file=TRAIN_2018_LABELS, \n",
    "    root_dir=TRAIN_2018_ROOT_DIR, \n",
    "    transform=preprocess_inceptionv3,\n",
    "    image_file_type=\"jpg\",\n",
    "    nrows=1000 # defines the number of rows used, utilized this for testing purposes\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/fritt/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "0it [00:00, ?it/s]/var/folders/pc/5ytjzw0165n86jc4_pv2802c0000gn/T/ipykernel_86630/435358437.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float)\n",
      "32it [01:33,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 1.2663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:46,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 1.0249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:31,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:28,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:29,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.8903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 0.8805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.7899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 loss: 0.7598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 loss: 0.7734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 loss: 0.7698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 loss: 0.7397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:26,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 loss: 0.7636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:32,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 loss: 0.7142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:37,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 loss: 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:32,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 loss: 0.7006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:32,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss: 0.7591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [01:35,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 loss: 0.6993\n",
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the data loader\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset_2018, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Load the pretrained Inception v3 model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "\n",
    "# Freeze the model parameters to prevent backpropagation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer with a new layer that matches the number of classes in the dataset\n",
    "num_classes = len(train_dataset_2018.annotations.columns)-1\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Train the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(data_loader, 0)):\n",
    "        inputs, labels = data\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, x = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch {} loss: {:.4f}'.format(epoch + 1, running_loss / (i + 1)))\n",
    "\n",
    "print('Finished training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set 2018 - custom class\n",
    "test_dataset_2018 = ISICDataset(\n",
    "    csv_file=TEST_2018_LABELS, \n",
    "    root_dir=TEST_2018_ROOT_DIR, \n",
    "    transform=preprocess_inceptionv3,\n",
    "    image_file_type=\"jpg\",\n",
    "    # nrows=200 # defines the number of rows used, utilized this for testing purposes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/5ytjzw0165n86jc4_pv2802c0000gn/T/ipykernel_86630/1444349468.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 68.91%\n"
     ]
    }
   ],
   "source": [
    "# Load the test set\n",
    "test_dataset = test_dataset_2018 # Define the test set in the same way as the training set\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        outputs = model(inputs)\n",
    "        labels = torch.argmax(labels)\n",
    "        predicted = torch.argmax(outputs.data)\n",
    "        total += 1\n",
    "        if labels==predicted:\n",
    "            correct += 1\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the model on the test set: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(data_loader, 0)):\n",
    "        inputs, labels = data\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, x = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_mit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 09:18:20) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d72a89182fe57c71d19a93846167a2ed969f783f236f2b4cdeac57cf0664951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
