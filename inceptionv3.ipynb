{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import torch # Import the Pytorch library\n",
    "import torchvision # Import the torchvision library\n",
    "from torchvision import transforms # Import the transforms module from torchvision\n",
    "\n",
    "from PIL import Image # Import the Image module from the Python Imaging Library (PIL)\n",
    "\n",
    "import urllib # Import the urllib library for URL handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRETRAINED MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/fritt/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the pre-trained Inception v3 model from the Pytorch hub\n",
    "# The 'pytorch/vision:v0.10.0' is the repository where the model is located\n",
    "# 'inception_v3' is the name of the model\n",
    "# The 'pretrained=True' flag loads the pre-trained weights\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "\n",
    "# Setting the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "\n",
    "# URL of the image to be downloaded\n",
    "url = \"https://github.com/pytorch/hub/raw/master/images/dog.jpg\"\n",
    "\n",
    "# Name to be given to the downloaded image file\n",
    "filename = \"local_files/dog.jpg\"\n",
    "\n",
    "# Try to download the image using the urllib.URLopener() method (for Python 2)\n",
    "try:\n",
    "    urllib.URLopener().retrieve(url, filename)\n",
    "\n",
    "# If the above method fails, use the urllib.request.urlretrieve() method (for Python 3)\n",
    "except:\n",
    "    urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.5696e-01,  1.1051e-01, -4.4363e-01, -6.1476e-02, -2.0093e-01,\n",
      "         1.6820e-01,  5.8117e-01,  6.0332e-02, -7.7653e-02, -1.1192e+00,\n",
      "        -2.1800e-01, -5.2624e-01, -1.1816e-01,  6.6276e-02,  8.4988e-01,\n",
      "        -5.3259e-02, -4.7113e-01, -2.5993e-03,  2.7504e-01,  1.7060e-01,\n",
      "         4.4231e-01, -3.8615e-01,  1.3482e-01, -5.2202e-01, -3.3703e-04,\n",
      "        -2.3492e-01, -2.3264e-01, -7.1883e-03,  1.6899e-02, -1.2724e-01,\n",
      "         2.0508e-01, -6.9887e-03,  1.3074e+00, -2.3181e-01,  9.8966e-01,\n",
      "        -7.7782e-01,  4.8900e-01, -4.2244e-01, -2.6523e-01, -1.5005e-01,\n",
      "         3.5147e-01, -1.7462e-01,  1.0251e-01,  4.2223e-01, -1.4342e-01,\n",
      "         1.3578e-02, -4.6477e-01,  3.5966e-01,  1.5194e-01,  2.0217e-01,\n",
      "        -1.3763e-01,  1.4986e-01,  2.8415e-01, -3.7086e-01,  9.7689e-01,\n",
      "         7.9543e-01, -7.4033e-01, -7.8853e-02, -9.6366e-02,  1.2193e-01,\n",
      "        -1.2712e-01,  3.6825e-01, -4.5355e-01, -7.4801e-01, -7.9356e-02,\n",
      "         2.1688e-01,  2.7018e-01,  1.0089e+00,  4.0730e-01, -1.8570e-01,\n",
      "        -9.2469e-02, -1.2458e-01, -1.0435e+00, -4.0775e-01,  1.8339e-01,\n",
      "        -2.7525e-01, -2.9294e-01,  1.6333e-02,  2.8761e-02,  2.0185e-01,\n",
      "        -4.8364e-01, -7.0670e-02,  1.6896e-01, -4.6967e-02,  8.4163e-01,\n",
      "        -3.6729e-01, -3.0113e-01, -3.7112e-01,  2.6911e-01,  3.7275e-01,\n",
      "         1.8055e-01,  3.1312e-01,  4.5380e-01, -1.3350e-01, -2.9443e-01,\n",
      "        -2.7947e-01,  8.4207e-01, -2.3104e-01, -3.1553e-01, -4.3883e-02,\n",
      "         1.5329e-01,  3.1552e-01,  1.8616e-01, -9.6862e-02,  4.7281e-01,\n",
      "        -8.9032e-01, -7.2464e-01,  2.3588e-01,  6.6725e-01,  1.3802e-01,\n",
      "        -2.4249e-01, -2.3605e-02, -5.4462e-02,  4.9208e-01,  4.9702e-02,\n",
      "        -5.8998e-01, -7.7230e-01,  1.3981e-01, -8.2220e-01,  3.9935e-02,\n",
      "         1.7365e-01, -1.0092e+00, -6.9951e-03, -2.6625e-01, -2.8959e-01,\n",
      "        -6.6460e-02, -6.4817e-01,  9.3626e-01,  5.5003e-01,  5.2842e-01,\n",
      "         1.0856e-01,  1.8085e-01,  6.0891e-01, -6.0835e-01,  3.3635e-01,\n",
      "         1.8864e-01,  5.8985e-01, -4.0940e-01, -7.3610e-01, -6.2800e-01,\n",
      "        -2.7593e-01,  2.6514e-01, -7.5665e-01,  2.5088e-01,  9.6007e-01,\n",
      "        -9.4858e-02,  3.0636e-01, -2.7368e-02,  3.5943e-02,  1.7601e-01,\n",
      "        -2.8860e-01,  1.6987e-01,  2.4232e+00, -1.2510e-01,  9.1045e-01,\n",
      "        -8.8260e-01, -5.1855e-02,  2.1003e+00, -6.6269e-01, -2.4618e-01,\n",
      "        -8.5638e-01, -1.3153e+00, -1.1042e+00, -2.4547e-01, -1.3737e-01,\n",
      "        -1.1962e-01, -2.0865e-01, -3.6327e-01, -9.5905e-02,  7.0066e-01,\n",
      "        -2.2363e-01, -1.8417e-01, -8.5439e-01, -1.8439e-01,  1.3066e+00,\n",
      "        -4.8575e-01, -5.6697e-01, -1.9955e-01, -1.6855e-01, -1.4573e-01,\n",
      "        -8.5888e-01, -3.4338e-01, -2.9275e-01, -4.5627e-01, -5.1301e-01,\n",
      "         4.3903e-01,  8.0301e-01, -4.9003e-01, -6.9808e-01, -8.5991e-01,\n",
      "        -4.1795e-01, -4.4660e-01,  2.0680e-01, -1.2265e+00, -4.5363e-01,\n",
      "        -5.2789e-01, -1.1172e+00,  2.6781e-01, -4.5858e-01,  2.8015e-01,\n",
      "         6.0328e-01, -8.8579e-01, -8.8179e-01,  1.4860e+00, -4.7116e-01,\n",
      "        -1.1044e+00, -5.9475e-01,  6.3241e-01, -5.9048e-01, -7.0500e-01,\n",
      "        -3.8798e-01, -6.3180e-01, -2.1158e-01, -1.6535e-01,  6.3881e-01,\n",
      "         2.8980e-02,  4.5989e-01,  8.4378e-02, -5.4092e-02, -1.9021e+00,\n",
      "        -1.1602e-01, -2.3897e-01,  2.5432e+00,  1.7504e+00,  1.3806e+00,\n",
      "        -5.3401e-01,  3.4183e-01, -7.0692e-01,  3.1853e-01, -9.9138e-02,\n",
      "         1.1112e+00,  1.2860e+00,  1.0465e+00, -7.3274e-02, -2.3343e-01,\n",
      "         6.5050e-02,  5.4067e-01, -4.5558e-01, -8.5780e-02, -4.2101e-01,\n",
      "         7.2590e-01,  4.5586e-01, -8.7705e-02, -8.4019e-01, -3.2783e-01,\n",
      "        -5.2903e-01, -4.2849e-01,  4.9993e-01,  3.2688e+00,  2.3975e+00,\n",
      "         1.5311e+00, -2.0808e-01, -1.8428e-01, -2.8011e-01, -1.7841e-01,\n",
      "         2.8461e-01,  5.3146e-01,  2.8738e+00,  8.8523e+00,  4.2019e+00,\n",
      "         2.5316e+00,  3.9927e+00, -3.1314e-01, -6.2400e-01, -2.6323e-01,\n",
      "        -2.3428e-01, -3.3132e-01,  1.7870e-01, -4.0714e-01,  8.2184e-01,\n",
      "         4.6482e+00, -8.9972e-01, -3.8765e-01,  6.0829e-01,  3.4514e-01,\n",
      "        -8.4613e-01, -7.5300e-02,  5.9165e-01, -2.2571e-01,  4.7909e+00,\n",
      "         2.8114e-01, -3.3872e-01, -7.5726e-01,  1.2868e+00, -6.3885e-01,\n",
      "        -7.2032e-01, -1.0338e+00,  2.1799e-01, -5.7312e-02,  1.2854e-01,\n",
      "        -4.6507e-01,  3.5065e-02, -3.6578e-01, -4.7805e-02, -9.9203e-01,\n",
      "        -1.3356e+00,  6.5032e-01, -2.7167e-01, -6.8011e-01, -5.7143e-01,\n",
      "        -5.3475e-01, -3.8411e-01, -6.4809e-02, -2.8354e-01, -1.7806e-01,\n",
      "        -2.8928e-02,  2.4240e-01, -1.7973e-01,  1.8139e-01, -1.5519e-01,\n",
      "        -2.3687e-01,  1.5365e-01, -1.1673e-01, -2.9109e-01,  2.4691e-01,\n",
      "         2.1827e-01, -5.1025e-01,  2.5870e-01, -1.6245e-01, -2.7104e-01,\n",
      "         4.1199e-01, -3.9074e-01, -6.5319e-01,  2.0439e-01, -1.2711e+00,\n",
      "        -4.3313e-01,  1.5427e-01,  3.4154e-01,  8.7113e-01, -4.1167e-02,\n",
      "        -1.8232e-01,  3.9798e-01,  9.8626e-01, -4.9940e-01, -2.1772e-02,\n",
      "        -5.8458e-01, -9.3022e-01, -5.0841e-01,  1.4682e-02, -2.6315e-01,\n",
      "         1.1864e-02, -1.7344e-01, -2.2880e-01, -2.0762e-01, -2.8182e-01,\n",
      "         3.0904e-02,  5.7570e-01,  3.2597e-01, -1.9836e-01, -8.1336e-01,\n",
      "        -5.2461e-01, -1.6578e-01, -4.2071e-01, -1.4268e-01, -2.6060e-01,\n",
      "         1.3962e-01, -8.4469e-02, -2.1359e-01,  7.6789e-01,  5.5213e-01,\n",
      "        -1.0924e+00,  6.3716e-01, -7.3622e-01,  4.3754e-01, -7.7834e-01,\n",
      "        -7.9443e-01, -1.4501e+00, -7.9228e-01, -7.8784e-01, -8.8925e-01,\n",
      "         2.0367e-01, -4.4673e-01, -9.1861e-01,  6.8157e-02, -2.8454e-01,\n",
      "        -3.7750e-01, -9.7066e-01,  1.0829e-01, -4.9947e-01, -1.3005e+00,\n",
      "        -7.6300e-01, -6.5802e-01, -7.3246e-01, -1.0341e+00, -1.2842e+00,\n",
      "        -3.6779e-01, -9.8348e-01, -9.7599e-02, -4.1649e-01, -6.8749e-02,\n",
      "        -3.5764e-01, -3.6454e-01,  2.1046e-01,  5.5320e-01, -2.1323e-01,\n",
      "        -2.6107e-01,  4.5051e-01, -7.4767e-02,  5.1910e-01,  1.7004e-01,\n",
      "        -3.2708e-02, -1.0269e+00,  5.5582e-01,  1.5760e-01,  9.7133e-02,\n",
      "         1.8764e-01, -3.2566e-01, -3.2677e-01,  2.5147e-01, -2.8530e-01,\n",
      "        -5.9853e-01, -1.0255e+00, -5.6512e-01, -3.8385e-01, -4.1670e-01,\n",
      "        -5.8828e-01, -6.2122e-01,  1.9794e-01, -4.6862e-01,  1.3163e-01,\n",
      "        -2.0324e-01, -1.0149e+00, -2.3162e-01,  1.7283e-01, -4.8196e-01,\n",
      "         2.5326e-01,  1.6461e-01,  6.2808e-02, -2.2099e-01,  2.0254e-01,\n",
      "        -1.6538e-01, -3.9705e-01,  2.4437e-01,  1.6360e-01, -7.2684e-01,\n",
      "        -1.0390e-02, -1.9011e-02, -3.1348e-01, -5.3056e-01,  8.2013e-02,\n",
      "         5.7136e-01, -3.0761e-01,  3.8100e-01, -6.4842e-01,  8.9465e-02,\n",
      "         4.7818e-01, -7.8970e-01, -3.4117e-01,  4.7726e-01,  1.5669e-01,\n",
      "        -1.8339e-01, -1.3243e-01,  2.3160e-01, -5.0399e-01, -2.2604e-01,\n",
      "         7.9325e-02,  5.2133e-01,  1.5784e-01, -8.6526e-02,  3.0305e-01,\n",
      "         9.7811e-02, -1.2771e+00,  7.0310e-01,  1.4597e-01,  3.2879e-01,\n",
      "        -3.6155e-01, -6.2039e-01, -8.8755e-01,  4.2935e-01,  1.1274e-01,\n",
      "         3.2891e-01,  8.4746e-02,  6.9849e-02,  8.1301e-01, -8.0782e-01,\n",
      "        -6.8245e-01,  1.3358e+00, -2.6256e-01,  8.9051e-01,  1.6758e-01,\n",
      "        -1.2170e-01,  4.2807e-01, -1.0054e+00,  3.5863e-01,  3.6240e-01,\n",
      "        -8.2987e-01,  2.9833e-01,  3.9784e-02,  3.5029e-01, -2.0015e-04,\n",
      "         1.4194e-02,  4.7898e-01, -5.8930e-01, -2.8985e-01, -1.0249e-01,\n",
      "         7.4155e-01,  2.6986e-01, -4.4872e-01, -1.5987e-01,  4.8277e-01,\n",
      "        -6.3190e-01, -2.1434e-01,  5.0953e-01, -6.9076e-01, -7.4333e-01,\n",
      "         2.0042e-01,  7.0910e-02,  1.0657e-02,  1.4496e-01, -6.7097e-01,\n",
      "         2.4766e-01,  7.7923e-01,  5.2101e-02, -3.9851e-01,  1.6331e-01,\n",
      "         1.0057e-01, -9.3775e-01, -5.3325e-01, -7.2511e-01, -1.2609e+00,\n",
      "        -2.4719e-01,  7.4883e-01,  1.0540e+00, -6.8609e-01, -1.6086e-01,\n",
      "        -4.3294e-01, -5.9875e-01, -7.0206e-01, -3.7986e-01, -5.7893e-01,\n",
      "         3.0747e-01, -2.1241e-02,  3.5246e-01, -2.5119e-01, -9.3378e-04,\n",
      "        -3.0555e-01, -1.0011e+00,  6.5736e-01, -1.9259e-02,  5.2677e-01,\n",
      "        -1.0669e-01, -3.7793e-01, -5.3913e-01,  1.4208e-01,  4.4693e-01,\n",
      "        -3.1716e-01,  3.0778e-01, -9.3853e-02, -6.7916e-01,  2.7398e-01,\n",
      "        -1.5625e-01,  2.8923e-01, -1.1230e-01, -1.1010e+00, -7.9937e-02,\n",
      "        -4.0612e-01,  2.0850e-02,  3.4710e-01,  4.3527e-02,  4.1308e-01,\n",
      "        -2.4231e-01, -9.4655e-01,  5.9508e-01,  4.2502e-01,  2.0579e-01,\n",
      "        -2.1273e-01,  3.5352e-02,  2.6313e-01, -2.9305e-01, -4.8487e-01,\n",
      "        -1.3051e-01, -6.9740e-01,  2.2013e-04,  7.6510e-01, -1.5280e-01,\n",
      "        -3.3351e-01,  3.0998e-01, -1.2360e-01,  3.9550e-01, -2.5940e-01,\n",
      "         6.4829e-02,  2.7397e-01, -1.5634e-01, -1.5518e-03,  6.4023e-01,\n",
      "         4.5707e-01, -7.3576e-01,  3.0117e-01, -4.9941e-01, -7.1722e-02,\n",
      "         4.7880e-01,  3.9970e-02,  6.5618e-01,  4.1189e-01,  4.7485e-01,\n",
      "        -6.1536e-01,  9.2373e-01,  1.2427e-01, -6.0887e-01, -3.6679e-01,\n",
      "        -6.6266e-01, -4.1378e-01,  8.5643e-02, -3.5291e-01,  9.0650e-01,\n",
      "        -2.6774e-01,  9.3556e-01,  2.5814e-01,  5.2646e-01,  1.5271e-01,\n",
      "         1.0879e-01, -9.9208e-02, -1.6872e-02,  3.1704e-02, -5.9293e-01,\n",
      "         3.7246e-02, -9.2498e-01, -5.0368e-01, -5.5661e-01, -5.3738e-01,\n",
      "        -5.1410e-01,  2.1919e-01,  5.5329e-01,  2.3826e-01,  6.1928e-02,\n",
      "         3.1898e-01,  2.5531e-01,  2.5802e-01,  5.3433e-01,  3.1997e-01,\n",
      "         1.0069e-01, -5.5496e-01, -3.7057e-01, -3.0339e-01, -1.5533e+00,\n",
      "        -5.9777e-01,  1.9452e-01, -3.6390e-01, -1.8436e-01,  5.1854e-01,\n",
      "        -2.0573e-01,  1.6028e-01, -4.1792e-01, -5.1243e-01, -1.3041e-01,\n",
      "         6.7688e-01,  5.5768e-01, -5.3552e-01, -3.6445e-01,  3.2987e-01,\n",
      "        -2.2301e-01,  1.1296e-01,  3.6002e-01, -2.2909e-01, -1.2944e-01,\n",
      "        -6.5538e-01,  4.0743e-01, -7.1308e-01, -2.8129e-01,  2.4215e-01,\n",
      "        -4.6964e-01, -2.4974e-02,  4.9898e-01, -8.8002e-01, -5.2670e-01,\n",
      "         1.7427e-01, -4.2441e-01,  7.8662e-01, -5.3916e-01,  3.1065e-01,\n",
      "         2.8586e-01, -3.8322e-01,  9.9570e-01, -1.5867e-01,  3.1807e-01,\n",
      "         5.9172e-01,  5.0590e-01, -1.8767e-01,  1.1740e-01,  6.0312e-01,\n",
      "         5.3131e-01, -4.3882e-01,  8.9231e-01,  1.0978e-01,  2.9768e-01,\n",
      "        -1.7924e-01, -3.8839e-01, -1.0702e-01, -1.8214e-01, -5.4149e-02,\n",
      "         3.7220e-01, -8.1579e-01, -5.9575e-01, -8.2093e-01, -4.2120e-01,\n",
      "         7.8664e-01, -1.8654e-01, -1.3514e-01,  3.9489e-01,  2.2791e-01,\n",
      "        -4.9966e-01, -2.2099e-01, -9.7539e-01,  4.4585e-01, -5.9411e-01,\n",
      "        -1.5309e+00,  6.6478e-01,  3.2396e-02, -3.4876e-01, -6.6410e-01,\n",
      "         1.0171e-01, -5.4312e-02,  1.1208e-01, -1.3051e+00,  2.9222e-01,\n",
      "         2.2820e-02, -3.7351e-01,  3.6517e-01,  5.8418e-01,  5.4525e-01,\n",
      "         1.4772e-01, -6.7846e-01,  4.3452e-01,  8.1183e-01,  9.4164e-01,\n",
      "        -1.6587e-01,  2.9264e-01,  1.0431e-01, -9.7528e-01,  8.0652e-01,\n",
      "        -5.1974e-01,  6.7096e-01, -6.9639e-02,  3.8821e-01, -1.3328e-01,\n",
      "        -5.3379e-01, -2.1545e-01, -3.0923e-02,  5.2758e-01, -6.4225e-01,\n",
      "         7.4214e-01, -9.9085e-02, -2.2626e-01, -8.4757e-01, -1.4464e-01,\n",
      "        -4.9659e-01,  9.6384e-01, -3.6248e-01, -4.5590e-01,  1.7444e-01,\n",
      "        -8.6812e-01, -3.6270e-01, -8.3891e-02, -6.0712e-01, -8.8571e-01,\n",
      "        -5.2017e-01, -1.0796e-01, -1.1842e-01,  7.4888e-01, -3.6315e-01,\n",
      "        -3.6594e-01, -6.3173e-01, -2.1045e-02,  5.7322e-01, -5.0686e-01,\n",
      "         3.6577e-01, -5.8337e-01,  2.4674e-01,  5.8519e-01,  5.8704e-01,\n",
      "        -1.0922e-01, -2.2033e-01, -1.0274e-01, -2.9973e-01,  1.1981e-01,\n",
      "         1.4440e-02,  1.7718e-01, -1.6776e-02, -5.2703e-01,  6.3708e-03,\n",
      "         8.5908e-01, -9.0771e-02,  8.8934e-02, -5.2244e-01,  1.6886e-01,\n",
      "        -6.9570e-02, -3.6008e-01, -4.3534e-01,  7.3869e-01,  1.0145e-02,\n",
      "         4.2083e-02,  3.1878e-01,  4.9873e-01, -3.8344e-01, -5.5373e-01,\n",
      "        -3.9139e-01, -5.0552e-01, -8.1061e-01, -2.1466e-01,  4.6706e-01,\n",
      "         8.1061e-02, -2.4330e-02,  2.2417e-01,  1.7968e-01, -6.6669e-01,\n",
      "         8.8543e-03, -1.0320e+00, -8.4254e-01,  8.3238e-02,  2.0019e-01,\n",
      "         8.5449e-01, -4.4028e-01,  1.2960e-01,  9.1979e-01,  5.6936e-01,\n",
      "         5.6918e-01,  2.3873e-01, -9.7529e-03, -2.6828e-01, -4.3488e-01,\n",
      "        -3.1654e-01, -6.7525e-01,  8.9602e-02, -3.8492e-01,  1.8651e-01,\n",
      "         4.2964e-01,  1.6951e-01, -2.1721e-01,  4.9334e-01, -6.4151e-01,\n",
      "        -1.9921e-01,  3.0178e-01,  6.5254e-01,  1.3441e-01, -4.5364e-01,\n",
      "        -4.3964e-01,  9.3067e-01,  4.9213e-02,  7.9005e-01, -2.7947e-01,\n",
      "        -1.2861e-01, -1.1192e-01, -9.7574e-03,  9.0923e-01,  1.2004e+00,\n",
      "        -2.4724e-01, -4.1714e-01, -7.1684e-01,  1.0332e-01, -1.7323e-01,\n",
      "        -3.5574e-01, -8.4381e-01,  1.1730e+00,  5.6873e-01,  2.5399e-01,\n",
      "        -4.8529e-01, -5.6345e-01,  5.7963e-01,  5.7392e-01, -7.4178e-02,\n",
      "         1.5523e-01,  1.7210e-01, -3.5009e-01,  1.6301e-01, -8.3165e-01,\n",
      "        -9.8661e-01, -6.0109e-01, -1.2554e-01, -1.7448e+00, -3.2454e-01,\n",
      "         3.0875e-01, -3.3978e-01,  2.9525e-02, -1.3952e-01, -2.8140e-01,\n",
      "        -4.4984e-01, -3.4723e-01, -1.0021e+00,  4.8977e-01,  2.6022e-02,\n",
      "        -1.0131e+00, -4.7002e-01, -8.9715e-02, -1.0494e+00, -1.0178e-01,\n",
      "         3.8124e-02,  1.4666e-01, -2.0754e-01,  9.7096e-02,  4.6701e-01,\n",
      "        -5.9060e-02,  6.0505e-02,  5.6262e-02,  6.5830e-01, -6.8960e-01,\n",
      "        -3.5968e-01,  6.2219e-01,  2.6003e-01,  6.1821e-01,  2.0742e-01,\n",
      "         3.5914e-02, -9.6990e-01,  3.3507e-01, -8.0717e-01, -4.2299e-01,\n",
      "        -4.4527e-01, -1.5236e-01,  2.7860e-01, -1.5024e-02, -1.8272e-01,\n",
      "         6.1362e-01,  2.7269e-01,  5.0595e-01,  8.9930e-01,  4.3492e-01,\n",
      "         7.4886e-01, -3.3694e-02, -4.8587e-01,  1.9098e-02,  9.8968e-02,\n",
      "        -7.8338e-02,  2.5597e-01,  5.0859e-01,  5.3146e-01, -5.5359e-01,\n",
      "         1.4253e-01, -2.6811e-01, -4.0937e-01, -5.3443e-02,  5.1993e-01,\n",
      "         6.1826e-01, -7.5056e-01, -6.7039e-01, -6.2210e-01, -7.4448e-01,\n",
      "         2.0625e-01, -2.5697e-01,  2.4676e-01, -3.3508e-01,  7.6297e-01,\n",
      "         3.1534e-01,  5.6650e-01,  6.5713e-01, -7.9393e-02,  7.7678e-01,\n",
      "         6.8465e-01,  1.8104e-01, -5.7682e-01,  2.3148e-01,  1.8354e-01,\n",
      "         5.3264e-01,  1.0745e-01,  5.9151e-01,  1.6822e-01,  3.3482e-01,\n",
      "         2.4336e-01,  3.8000e-01,  2.3643e-01,  8.1279e-02, -1.6266e-01,\n",
      "        -2.0972e-01,  3.6127e-01,  1.7537e-01, -2.2607e-02, -3.1598e-01,\n",
      "        -3.0899e-01,  2.6050e-01,  1.6448e-01, -8.3392e-01,  2.4559e-01,\n",
      "        -1.7998e-02, -5.8638e-02,  5.7999e-01,  2.5527e-02,  1.6725e-01,\n",
      "        -2.6779e-01,  1.6889e-01,  1.3000e+00,  7.3652e-01,  2.6302e-01,\n",
      "        -2.7671e-01, -2.4274e-01, -2.1896e-01,  1.6211e-01, -3.1851e-01,\n",
      "         3.9199e-02,  1.4024e-01, -4.0862e-01,  1.9422e-01, -9.6028e-02,\n",
      "        -3.0628e-01, -3.8949e-01, -1.8944e-01, -9.0315e-01, -8.7265e-01,\n",
      "        -4.3267e-01, -7.3840e-02, -8.3184e-01, -5.2276e-01,  1.1610e-01])\n",
      "tensor([1.3789e-04, 1.3163e-04, 7.5630e-05, 1.1083e-04, 9.6404e-05, 1.3945e-04,\n",
      "        2.1075e-04, 1.2519e-04, 1.0905e-04, 3.8484e-05, 9.4773e-05, 6.9633e-05,\n",
      "        1.0472e-04, 1.2593e-04, 2.7572e-04, 1.1175e-04, 7.3579e-05, 1.1755e-04,\n",
      "        1.5517e-04, 1.3978e-04, 1.8342e-04, 8.0105e-05, 1.3487e-04, 6.9928e-05,\n",
      "        1.1782e-04, 9.3183e-05, 9.3396e-05, 1.1701e-04, 1.1987e-04, 1.0378e-04,\n",
      "        1.4469e-04, 1.1704e-04, 4.3569e-04, 9.3473e-05, 3.1708e-04, 5.4145e-05,\n",
      "        1.9219e-04, 7.7250e-05, 9.0401e-05, 1.0144e-04, 1.6750e-04, 9.8975e-05,\n",
      "        1.3058e-04, 1.7978e-04, 1.0211e-04, 1.1947e-04, 7.4048e-05, 1.6887e-04,\n",
      "        1.3720e-04, 1.4427e-04, 1.0270e-04, 1.3691e-04, 1.5659e-04, 8.1339e-05,\n",
      "        3.1305e-04, 2.6110e-04, 5.6214e-05, 1.0892e-04, 1.0703e-04, 1.3314e-04,\n",
      "        1.0379e-04, 1.7033e-04, 7.4884e-05, 5.5784e-05, 1.0887e-04, 1.4640e-04,\n",
      "        1.5442e-04, 3.2324e-04, 1.7711e-04, 9.7885e-05, 1.0745e-04, 1.0405e-04,\n",
      "        4.1513e-05, 7.8393e-05, 1.4158e-04, 8.9500e-05, 8.7931e-05, 1.1980e-04,\n",
      "        1.2130e-04, 1.4422e-04, 7.2664e-05, 1.0982e-04, 1.3955e-04, 1.1245e-04,\n",
      "        2.7345e-04, 8.1630e-05, 8.7214e-05, 8.1318e-05, 1.5425e-04, 1.7110e-04,\n",
      "        1.4118e-04, 1.6119e-04, 1.8554e-04, 1.0313e-04, 8.7799e-05, 8.9123e-05,\n",
      "        2.7357e-04, 9.3545e-05, 8.5966e-05, 1.1280e-04, 1.3738e-04, 1.6158e-04,\n",
      "        1.4197e-04, 1.0698e-04, 1.8910e-04, 4.8384e-05, 5.7102e-05, 1.4921e-04,\n",
      "        2.2969e-04, 1.3530e-04, 9.2480e-05, 1.1511e-04, 1.1161e-04, 1.9278e-04,\n",
      "        1.2386e-04, 6.5333e-05, 5.4445e-05, 1.3554e-04, 5.1795e-05, 1.2266e-04,\n",
      "        1.4021e-04, 4.2960e-05, 1.1704e-04, 9.0309e-05, 8.8225e-05, 1.1028e-04,\n",
      "        6.1640e-05, 3.0059e-04, 2.0428e-04, 1.9992e-04, 1.3137e-04, 1.4122e-04,\n",
      "        2.1668e-04, 6.4144e-05, 1.6498e-04, 1.4233e-04, 2.1258e-04, 7.8264e-05,\n",
      "        5.6451e-05, 6.2896e-05, 8.9439e-05, 1.5364e-04, 5.5303e-05, 1.5147e-04,\n",
      "        3.0783e-04, 1.0719e-04, 1.6011e-04, 1.1468e-04, 1.2217e-04, 1.4054e-04,\n",
      "        8.8313e-05, 1.3968e-04, 1.3296e-03, 1.0400e-04, 2.9293e-04, 4.8759e-05,\n",
      "        1.1190e-04, 9.6276e-04, 6.0752e-05, 9.2139e-05, 5.0054e-05, 3.1633e-05,\n",
      "        3.9066e-05, 9.2205e-05, 1.0273e-04, 1.0457e-04, 9.5663e-05, 8.1958e-05,\n",
      "        1.0708e-04, 2.3749e-04, 9.4241e-05, 9.8034e-05, 5.0154e-05, 9.8013e-05,\n",
      "        4.3532e-04, 7.2511e-05, 6.6854e-05, 9.6538e-05, 9.9578e-05, 1.0188e-04,\n",
      "        4.9929e-05, 8.3605e-05, 8.7947e-05, 7.4680e-05, 7.0561e-05, 1.8282e-04,\n",
      "        2.6309e-04, 7.2201e-05, 5.8639e-05, 4.9878e-05, 7.7598e-05, 7.5406e-05,\n",
      "        1.4494e-04, 3.4571e-05, 7.4878e-05, 6.9518e-05, 3.8565e-05, 1.5405e-04,\n",
      "        7.4508e-05, 1.5597e-04, 2.1546e-04, 4.8604e-05, 4.8799e-05, 5.2084e-04,\n",
      "        7.3577e-05, 3.9061e-05, 6.5023e-05, 2.2183e-04, 6.5301e-05, 5.8235e-05,\n",
      "        7.9958e-05, 6.2658e-05, 9.5383e-05, 9.9897e-05, 2.2325e-04, 1.2132e-04,\n",
      "        1.8668e-04, 1.2823e-04, 1.1165e-04, 1.7592e-05, 1.0495e-04, 9.2806e-05,\n",
      "        1.4993e-03, 6.7850e-04, 4.6877e-04, 6.9094e-05, 1.6589e-04, 5.8123e-05,\n",
      "        1.6207e-04, 1.0673e-04, 3.5807e-04, 4.2645e-04, 3.3563e-04, 1.0953e-04,\n",
      "        9.3322e-05, 1.2578e-04, 2.0238e-04, 7.4732e-05, 1.0817e-04, 7.7360e-05,\n",
      "        2.4357e-04, 1.8593e-04, 1.0796e-04, 5.0871e-05, 8.4915e-05, 6.9440e-05,\n",
      "        7.6784e-05, 1.9430e-04, 3.0973e-03, 1.2960e-03, 5.4488e-04, 9.5718e-05,\n",
      "        9.8023e-05, 8.9066e-05, 9.8600e-05, 1.5666e-04, 2.0053e-04, 2.0865e-03,\n",
      "        8.2385e-01, 7.8746e-03, 1.4819e-03, 6.3878e-03, 8.6172e-05, 6.3148e-05,\n",
      "        9.0582e-05, 9.3243e-05, 8.4619e-05, 1.4092e-04, 7.8441e-05, 2.6809e-04,\n",
      "        1.2304e-02, 4.7931e-05, 7.9985e-05, 2.1654e-04, 1.6644e-04, 5.0570e-05,\n",
      "        1.0931e-04, 2.1297e-04, 9.4045e-05, 1.4192e-02, 1.5612e-04, 8.3996e-05,\n",
      "        5.5270e-05, 4.2677e-04, 6.2217e-05, 5.7350e-05, 4.1915e-05, 1.4657e-04,\n",
      "        1.1129e-04, 1.3403e-04, 7.4026e-05, 1.2206e-04, 8.1753e-05, 1.1236e-04,\n",
      "        4.3705e-05, 3.0996e-05, 2.2584e-04, 8.9820e-05, 5.9702e-05, 6.6557e-05,\n",
      "        6.9044e-05, 8.0268e-05, 1.1046e-04, 8.8761e-05, 9.8635e-05, 1.1450e-04,\n",
      "        1.5019e-04, 9.8471e-05, 1.4130e-04, 1.0092e-04, 9.3001e-05, 1.3743e-04,\n",
      "        1.0487e-04, 8.8093e-05, 1.5087e-04, 1.4661e-04, 7.0756e-05, 1.5266e-04,\n",
      "        1.0019e-04, 8.9877e-05, 1.7794e-04, 7.9738e-05, 6.1332e-05, 1.4459e-04,\n",
      "        3.3062e-05, 7.6429e-05, 1.3752e-04, 1.6584e-04, 2.8164e-04, 1.1311e-04,\n",
      "        9.8216e-05, 1.7547e-04, 3.1600e-04, 7.1528e-05, 1.1532e-04, 6.5687e-05,\n",
      "        4.6491e-05, 7.0886e-05, 1.1960e-04, 9.0590e-05, 1.1927e-04, 9.9092e-05,\n",
      "        9.3755e-05, 9.5762e-05, 8.8914e-05, 1.2156e-04, 2.0960e-04, 1.6328e-04,\n",
      "        9.6653e-05, 5.2254e-05, 6.9747e-05, 9.9854e-05, 7.7384e-05, 1.0219e-04,\n",
      "        9.0820e-05, 1.3552e-04, 1.0831e-04, 9.5192e-05, 2.5401e-04, 2.0472e-04,\n",
      "        3.9530e-05, 2.2288e-04, 5.6445e-05, 1.8255e-04, 5.4117e-05, 5.3253e-05,\n",
      "        2.7644e-05, 5.3367e-05, 5.3605e-05, 4.8436e-05, 1.4448e-04, 7.5396e-05,\n",
      "        4.7034e-05, 1.2617e-04, 8.8672e-05, 8.0801e-05, 4.4649e-05, 1.3134e-04,\n",
      "        7.1523e-05, 3.2104e-05, 5.4953e-05, 6.1036e-05, 5.6657e-05, 4.1905e-05,\n",
      "        3.2632e-05, 8.1589e-05, 4.4080e-05, 1.0690e-04, 7.7711e-05, 1.1003e-04,\n",
      "        8.2422e-05, 8.1855e-05, 1.4547e-04, 2.0493e-04, 9.5227e-05, 9.0778e-05,\n",
      "        1.8493e-04, 1.0937e-04, 1.9806e-04, 1.3970e-04, 1.1407e-04, 4.2206e-05,\n",
      "        2.0547e-04, 1.3798e-04, 1.2988e-04, 1.4218e-04, 8.5100e-05, 8.5006e-05,\n",
      "        1.5156e-04, 8.8605e-05, 6.4777e-05, 4.2265e-05, 6.6978e-05, 8.0290e-05,\n",
      "        7.7695e-05, 6.5445e-05, 6.3324e-05, 1.4366e-04, 7.3764e-05, 1.3444e-04,\n",
      "        9.6182e-05, 4.2716e-05, 9.3491e-05, 1.4009e-04, 7.2786e-05, 1.5183e-04,\n",
      "        1.3895e-04, 1.2550e-04, 9.4490e-05, 1.4432e-04, 9.9893e-05, 7.9236e-05,\n",
      "        1.5048e-04, 1.3881e-04, 5.6977e-05, 1.1664e-04, 1.1564e-04, 8.6142e-05,\n",
      "        6.9334e-05, 1.2793e-04, 2.0869e-04, 8.6650e-05, 1.7252e-04, 6.1625e-05,\n",
      "        1.2889e-04, 1.9012e-04, 5.3506e-05, 8.3790e-05, 1.8995e-04, 1.3785e-04,\n",
      "        9.8111e-05, 1.0324e-04, 1.4857e-04, 7.1200e-05, 9.4014e-05, 1.2759e-04,\n",
      "        1.9851e-04, 1.3801e-04, 1.0809e-04, 1.5958e-04, 1.2997e-04, 3.2863e-05,\n",
      "        2.3808e-04, 1.3638e-04, 1.6374e-04, 8.2100e-05, 6.3377e-05, 4.8518e-05,\n",
      "        1.8106e-04, 1.3192e-04, 1.6376e-04, 1.2828e-04, 1.2639e-04, 2.6574e-04,\n",
      "        5.2545e-05, 5.9563e-05, 4.4820e-04, 9.0643e-05, 2.8715e-04, 1.3936e-04,\n",
      "        1.0435e-04, 1.8083e-04, 4.3124e-05, 1.6870e-04, 1.6934e-04, 5.1399e-05,\n",
      "        1.5883e-04, 1.2264e-04, 1.6730e-04, 1.1784e-04, 1.1954e-04, 1.9027e-04,\n",
      "        6.5378e-05, 8.8203e-05, 1.0638e-04, 2.4741e-04, 1.5437e-04, 7.5246e-05,\n",
      "        1.0045e-04, 1.9100e-04, 6.2651e-05, 9.5121e-05, 1.9618e-04, 5.9070e-05,\n",
      "        5.6045e-05, 1.4401e-04, 1.2652e-04, 1.1912e-04, 1.3624e-04, 6.0251e-05,\n",
      "        1.5098e-04, 2.5691e-04, 1.2416e-04, 7.9121e-05, 1.3877e-04, 1.3033e-04,\n",
      "        4.6143e-05, 6.9147e-05, 5.7076e-05, 3.3399e-05, 9.2047e-05, 2.4921e-04,\n",
      "        3.3814e-04, 5.9347e-05, 1.0035e-04, 7.6443e-05, 6.4763e-05, 5.8407e-05,\n",
      "        8.0610e-05, 6.6059e-05, 1.6029e-04, 1.1538e-04, 1.6766e-04, 9.1680e-05,\n",
      "        1.1775e-04, 8.6828e-05, 4.3311e-05, 2.2743e-04, 1.1561e-04, 1.9959e-04,\n",
      "        1.0593e-04, 8.0766e-05, 6.8741e-05, 1.3585e-04, 1.8427e-04, 8.5826e-05,\n",
      "        1.6034e-04, 1.0730e-04, 5.9759e-05, 1.5501e-04, 1.0081e-04, 1.5739e-04,\n",
      "        1.0534e-04, 3.9192e-05, 1.0880e-04, 7.8521e-05, 1.2034e-04, 1.6677e-04,\n",
      "        1.2310e-04, 1.7814e-04, 9.2497e-05, 4.5738e-05, 2.1370e-04, 1.8028e-04,\n",
      "        1.4479e-04, 9.5274e-05, 1.2210e-04, 1.5333e-04, 8.7921e-05, 7.2574e-05,\n",
      "        1.0344e-04, 5.8679e-05, 1.1788e-04, 2.5330e-04, 1.0116e-04, 8.4435e-05,\n",
      "        1.6069e-04, 1.0416e-04, 1.7503e-04, 9.0930e-05, 1.2575e-04, 1.5500e-04,\n",
      "        1.0080e-04, 1.1768e-04, 2.2357e-04, 1.8615e-04, 5.6471e-05, 1.5928e-04,\n",
      "        7.1527e-05, 1.0970e-04, 1.9024e-04, 1.2266e-04, 2.2716e-04, 1.7793e-04,\n",
      "        1.8949e-04, 6.3696e-05, 2.9685e-04, 1.3345e-04, 6.4111e-05, 8.1671e-05,\n",
      "        6.0754e-05, 7.7922e-05, 1.2840e-04, 8.2812e-05, 2.9178e-04, 9.0174e-05,\n",
      "        3.0038e-04, 1.5257e-04, 1.9953e-04, 1.3730e-04, 1.3140e-04, 1.0673e-04,\n",
      "        1.1589e-04, 1.2166e-04, 6.5141e-05, 1.2233e-04, 4.6736e-05, 7.1222e-05,\n",
      "        6.7550e-05, 6.8862e-05, 7.0484e-05, 1.4674e-04, 2.0495e-04, 1.4957e-04,\n",
      "        1.2539e-04, 1.6214e-04, 1.5214e-04, 1.5255e-04, 2.0110e-04, 1.6230e-04,\n",
      "        1.3034e-04, 6.7662e-05, 8.1362e-05, 8.7017e-05, 2.4933e-05, 6.4827e-05,\n",
      "        1.4317e-04, 8.1907e-05, 9.8015e-05, 1.9795e-04, 9.5943e-05, 1.3835e-04,\n",
      "        7.7600e-05, 7.0602e-05, 1.0345e-04, 2.3191e-04, 2.0585e-04, 6.8991e-05,\n",
      "        8.1862e-05, 1.6392e-04, 9.4299e-05, 1.3195e-04, 1.6893e-04, 9.3728e-05,\n",
      "        1.0355e-04, 6.1197e-05, 1.7714e-04, 5.7766e-05, 8.8961e-05, 1.5015e-04,\n",
      "        7.3689e-05, 1.1495e-04, 1.9412e-04, 4.8885e-05, 6.9602e-05, 1.4030e-04,\n",
      "        7.7098e-05, 2.5881e-04, 6.8739e-05, 1.6080e-04, 1.5686e-04, 8.0340e-05,\n",
      "        3.1900e-04, 1.0057e-04, 1.6199e-04, 2.1298e-04, 1.9547e-04, 9.7691e-05,\n",
      "        1.3254e-04, 2.1542e-04, 2.0050e-04, 7.5995e-05, 2.8767e-04, 1.3153e-04,\n",
      "        1.5872e-04, 9.8518e-05, 7.9925e-05, 1.0590e-04, 9.8234e-05, 1.1165e-04,\n",
      "        1.7100e-04, 5.2128e-05, 6.4958e-05, 5.1861e-05, 7.7346e-05, 2.5882e-04,\n",
      "        9.7802e-05, 1.0296e-04, 1.7493e-04, 1.4803e-04, 7.1509e-05, 9.4490e-05,\n",
      "        4.4438e-05, 1.8407e-04, 6.5064e-05, 2.5497e-05, 2.2912e-04, 1.2174e-04,\n",
      "        8.3156e-05, 6.0666e-05, 1.3048e-04, 1.1163e-04, 1.3184e-04, 3.1956e-05,\n",
      "        1.5786e-04, 1.2058e-04, 8.1124e-05, 1.6981e-04, 2.1138e-04, 2.0331e-04,\n",
      "        1.3662e-04, 5.9801e-05, 1.8200e-04, 2.6542e-04, 3.0221e-04, 9.9845e-05,\n",
      "        1.5793e-04, 1.3082e-04, 4.4443e-05, 2.6401e-04, 7.0088e-05, 2.3055e-04,\n",
      "        1.0993e-04, 1.7376e-04, 1.0315e-04, 6.9110e-05, 9.5015e-05, 1.1427e-04,\n",
      "        1.9975e-04, 6.2006e-05, 2.4755e-04, 1.0674e-04, 9.3994e-05, 5.0497e-05,\n",
      "        1.0199e-04, 7.1729e-05, 3.0900e-04, 8.2024e-05, 7.4708e-05, 1.4032e-04,\n",
      "        4.9470e-05, 8.2005e-05, 1.0837e-04, 6.4223e-05, 4.8608e-05, 7.0057e-05,\n",
      "        1.0580e-04, 1.0470e-04, 2.4923e-04, 8.1969e-05, 8.1740e-05, 6.2662e-05,\n",
      "        1.1540e-04, 2.0908e-04, 7.0996e-05, 1.6991e-04, 6.5767e-05, 1.5084e-04,\n",
      "        2.1160e-04, 2.1199e-04, 1.0566e-04, 9.4552e-05, 1.0635e-04, 8.7335e-05,\n",
      "        1.3286e-04, 1.1957e-04, 1.4071e-04, 1.1590e-04, 6.9578e-05, 1.1861e-04,\n",
      "        2.7826e-04, 1.0763e-04, 1.2882e-04, 6.9898e-05, 1.3954e-04, 1.0994e-04,\n",
      "        8.2220e-05, 7.6260e-05, 2.4670e-04, 1.1906e-04, 1.2292e-04, 1.6211e-04,\n",
      "        1.9407e-04, 8.0322e-05, 6.7745e-05, 7.9686e-05, 7.1091e-05, 5.2398e-05,\n",
      "        9.5090e-05, 1.8802e-04, 1.2781e-04, 1.1503e-04, 1.4748e-04, 1.4106e-04,\n",
      "        6.0509e-05, 1.1891e-04, 4.1991e-05, 5.0752e-05, 1.2809e-04, 1.4398e-04,\n",
      "        2.7699e-04, 7.5884e-05, 1.3417e-04, 2.9568e-04, 2.0827e-04, 2.0823e-04,\n",
      "        1.4964e-04, 1.1671e-04, 9.0126e-05, 7.6295e-05, 8.5880e-05, 5.9993e-05,\n",
      "        1.2891e-04, 8.0204e-05, 1.4202e-04, 1.8111e-04, 1.3963e-04, 9.4848e-05,\n",
      "        1.9303e-04, 6.2052e-05, 9.6571e-05, 1.5938e-04, 2.2634e-04, 1.3481e-04,\n",
      "        7.4877e-05, 7.5932e-05, 2.9892e-04, 1.2380e-04, 2.5970e-04, 8.9123e-05,\n",
      "        1.0363e-04, 1.0538e-04, 1.1671e-04, 2.9257e-04, 3.9147e-04, 9.2042e-05,\n",
      "        7.7660e-05, 5.7550e-05, 1.3069e-04, 9.9113e-05, 8.2578e-05, 5.0687e-05,\n",
      "        3.8089e-04, 2.0814e-04, 1.5194e-04, 7.2544e-05, 6.7090e-05, 2.1042e-04,\n",
      "        2.0922e-04, 1.0943e-04, 1.3765e-04, 1.3999e-04, 8.3046e-05, 1.3873e-04,\n",
      "        5.1307e-05, 4.3942e-05, 6.4611e-05, 1.0395e-04, 2.0588e-05, 8.5195e-05,\n",
      "        1.6049e-04, 8.3907e-05, 1.2139e-04, 1.0251e-04, 8.8951e-05, 7.5162e-05,\n",
      "        8.3284e-05, 4.3266e-05, 1.9234e-04, 1.2097e-04, 4.2794e-05, 7.3660e-05,\n",
      "        1.0775e-04, 4.1266e-05, 1.0645e-04, 1.2244e-04, 1.3647e-04, 9.5769e-05,\n",
      "        1.2988e-04, 1.8801e-04, 1.1110e-04, 1.2521e-04, 1.2468e-04, 2.2764e-04,\n",
      "        5.9139e-05, 8.2254e-05, 2.1957e-04, 1.5286e-04, 2.1870e-04, 1.4502e-04,\n",
      "        1.2217e-04, 4.4683e-05, 1.6477e-04, 5.2579e-05, 7.7208e-05, 7.5506e-05,\n",
      "        1.0120e-04, 1.5572e-04, 1.1610e-04, 9.8176e-05, 2.1770e-04, 1.5481e-04,\n",
      "        1.9548e-04, 2.8968e-04, 1.8207e-04, 2.4922e-04, 1.1395e-04, 7.2502e-05,\n",
      "        1.2013e-04, 1.3012e-04, 1.0898e-04, 1.5224e-04, 1.9599e-04, 2.0053e-04,\n",
      "        6.7755e-05, 1.3591e-04, 9.0141e-05, 7.8266e-05, 1.1173e-04, 1.9823e-04,\n",
      "        2.1871e-04, 5.5641e-05, 6.0286e-05, 6.3268e-05, 5.5981e-05, 1.4486e-04,\n",
      "        9.1151e-05, 1.5084e-04, 8.4302e-05, 2.5276e-04, 1.6155e-04, 2.0768e-04,\n",
      "        2.2738e-04, 1.0886e-04, 2.5628e-04, 2.3372e-04, 1.4125e-04, 6.6199e-05,\n",
      "        1.4856e-04, 1.4160e-04, 2.0076e-04, 1.3123e-04, 2.1294e-04, 1.3945e-04,\n",
      "        1.6473e-04, 1.5033e-04, 1.7234e-04, 1.4929e-04, 1.2784e-04, 1.0017e-04,\n",
      "        9.5561e-05, 1.6914e-04, 1.4045e-04, 1.1522e-04, 8.5928e-05, 8.6530e-05,\n",
      "        1.5293e-04, 1.3893e-04, 5.1191e-05, 1.5067e-04, 1.1576e-04, 1.1115e-04,\n",
      "        2.1050e-04, 1.2091e-04, 1.3931e-04, 9.0170e-05, 1.3954e-04, 4.3246e-04,\n",
      "        2.4617e-04, 1.5332e-04, 8.9369e-05, 9.2457e-05, 9.4682e-05, 1.3860e-04,\n",
      "        8.5710e-05, 1.2257e-04, 1.3560e-04, 7.8325e-05, 1.4312e-04, 1.0707e-04,\n",
      "        8.6765e-05, 7.9838e-05, 9.7519e-05, 4.7767e-05, 4.9246e-05, 7.6464e-05,\n",
      "        1.0947e-04, 5.1297e-05, 6.9876e-05, 1.3237e-04])\n"
     ]
    }
   ],
   "source": [
    "# Open the downloaded image file\n",
    "input_image = Image.open(filename)\n",
    "\n",
    "# Define image pre-processing steps\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(299), # Resize the image to 299x299 pixels\n",
    "    transforms.CenterCrop(299), # Crop the image to 299x299 pixels (removing any extra pixels)\n",
    "    transforms.ToTensor(), # Convert the image to a Pytorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the image using the pre-trained model's mean and standard deviation\n",
    "])\n",
    "\n",
    "# Apply the pre-processing steps to the image\n",
    "input_tensor = preprocess(input_image)\n",
    "\n",
    "# Add a batch dimension to the image (required by the model)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Move the input and model to GPU for faster processing if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "# Disable gradient computation (not needed for inference)\n",
    "with torch.no_grad():\n",
    "    # Use the model to classify the image\n",
    "    output = model(input_batch)\n",
    "\n",
    "# The output has unnormalized scores for the 1000 ImageNet classes\n",
    "print(output[0])\n",
    "\n",
    "# To get the class probabilities, apply a softmax function on the output\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Print the class probabilities\n",
    "print(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ImageNet labels\n",
    "# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8238477110862732\n",
      "Arctic fox 0.014191544614732265\n",
      "white wolf 0.012303504161536694\n",
      "Pomeranian 0.007874640636146069\n",
      "keeshond 0.006387791130691767\n"
     ]
    }
   ],
   "source": [
    "# Read the categories from a text file\n",
    "with open(\"local_files/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "# Get the top 5 categories with the highest probabilities\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "# Print the top 5 categories and their probabilities\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_mit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d72a89182fe57c71d19a93846167a2ed969f783f236f2b4cdeac57cf0664951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
