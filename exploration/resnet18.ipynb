{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import torch # Import the Pytorch library\n",
    "import torchvision # Import the torchvision library\n",
    "from torchvision import datasets, transforms # Import the transforms module from torchvision\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image # Import the Image module from the Python Imaging Library (PIL)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import urllib # Import the urllib library for URL handling\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from customDataset import ISICDataset\n",
    "\n",
    "# HELPER FUNCTIONS\n",
    "from data_exploration_helper import dataset_overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONSTANTS\n",
    "Contains the `2018` and `2019` datasets, the `2018` dataset is split up into train and test. The `2019` dataset is not been split up into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 2018\n",
    "TRAIN_2018_LABELS: str = \"./data/ISIC2018_Training_GroundTruth.csv\"\n",
    "TRAIN_2018_ROOT_DIR: str = \"./data/ISIC2018_Training_Input\"\n",
    "\n",
    "TEST_2018_LABELS: str = \"./data/ISIC2018_Validation_GroundTruth.csv\"\n",
    "TEST_2018_ROOT_DIR: str = \"./data/ISIC2018_Validation_Input\"\n",
    "\n",
    "# Dataset 2019 - has not been split into train and test\n",
    "DATASET_2019_LABELS: str = \"./data/ISIC_2019_Training_GroundTruth.csv\"\n",
    "DATASET_2019_ROOT_DIR: str = \"./data/ISIC_2019_Training_Input\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image pre-processing steps\n",
    "preprocess_resnet18 = transforms.Compose([\n",
    "    transforms.ToPILImage(), # Removes potential errors in Inception V3, may need it here also\n",
    "    transforms.Resize(256),  # Resize the image to 256x256 pixels\n",
    "    transforms.CenterCrop(224), # Crop the image to 224x224 pixels (removing any extra pixels)\n",
    "    transforms.ToTensor(), # Convert the image to a Pytorch tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the image using the pre-trained model's mean and standard deviation\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset class & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set 2018 - custom class\n",
    "train_dataset_2018 = ISICDataset(\n",
    "    csv_file=TRAIN_2018_LABELS, \n",
    "    root_dir=TRAIN_2018_ROOT_DIR, \n",
    "    transform=preprocess_resnet18,\n",
    "    image_file_type=\"jpg\",\n",
    "    nrows=5000 # defines the number of rows used, utilized this for testing purposes\n",
    "    )\n",
    "\n",
    "# Define the data loader for the 2018 training set\n",
    "data_loader = torch.utils.data.DataLoader(train_dataset_2018, batch_size=32, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRETRAINED RESNET 18 MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/fritt/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/fritt/anaconda3/envs/adv_mit/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ResNet-18 model from the Pytorch hub\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True);\n",
    "\n",
    "# The following lines are alternative ways to load different variants of the ResNet model\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet34', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet101', pretrained=True)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet152', pretrained=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/var/folders/pc/5ytjzw0165n86jc4_pv2802c0000gn/T/ipykernel_90882/153649572.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float)\n",
      " 10%|█         | 1/10 [03:01<27:09, 181.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:00<24:01, 180.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 loss: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:56<20:48, 178.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 loss: 0.6743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [11:58<17:57, 179.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.6435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [15:03<15:08, 181.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 loss: 0.6158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [17:58<11:56, 179.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 loss: 0.6012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [20:48<08:48, 176.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 loss: 0.5762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [23:36<05:47, 173.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 loss: 0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [26:38<02:56, 176.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 loss: 0.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [29:44<00:00, 178.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 loss: 0.5471\n",
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Freeze the model parameters to prevent backpropagation\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final layer with a new layer that matches the number of classes in the dataset\n",
    "num_classes = len(train_dataset_2018.annotations.columns)-1\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Train the model\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in tqdm(range(10)):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        inputs, labels = data\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch {} loss: {:.4f}'.format(epoch + 1, running_loss / (i + 1)))\n",
    "\n",
    "print('Finished training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set 2018 - custom class\n",
    "test_dataset_2018 = ISICDataset(\n",
    "    csv_file=TEST_2018_LABELS, \n",
    "    root_dir=TEST_2018_ROOT_DIR, \n",
    "    transform=preprocess_resnet18,\n",
    "    image_file_type=\"jpg\",\n",
    "    # nrows=100 # defines the number of rows used, utilized this for testing purposes\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pc/5ytjzw0165n86jc4_pv2802c0000gn/T/ipykernel_90882/1444349468.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 77.20%\n"
     ]
    }
   ],
   "source": [
    "# Load the test set\n",
    "test_dataset = test_dataset_2018 # Define the test set in the same way as the training set\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "        outputs = model(inputs)\n",
    "        labels = torch.argmax(labels)\n",
    "        predicted = torch.argmax(outputs.data)\n",
    "        total += 1\n",
    "        if labels==predicted:\n",
    "            correct += 1\n",
    "    accuracy = 100 * correct / total\n",
    "    print('Accuracy of the model on the test set: {:.2f}%'.format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv_mit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d72a89182fe57c71d19a93846167a2ed969f783f236f2b4cdeac57cf0664951"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
